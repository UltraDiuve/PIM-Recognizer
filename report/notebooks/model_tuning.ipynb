{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning du modèle\n",
    "\n",
    "L'objet de ce notebook est d'illustrer les différentes étapes de tuning du modèle.\n",
    "\n",
    "\n",
    "## Préambule\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up sys.path for relative imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = str(Path(sys.path[0]).parents[1].absolute())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and customization of diplay\n",
    "# import os\n",
    "import re\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.min_rows = 6\n",
    "pd.options.display.width=108\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "from src.pimest import ContentGetter\n",
    "from src.pimest import PathGetter\n",
    "from src.pimest import PDFContentParser\n",
    "from src.pimest import BlockSplitter\n",
    "from src.pimest import SimilaritySelector\n",
    "# from src.pimest import custom_accuracy\n",
    "from src.pimest import text_sim_score\n",
    "# from src.pimest import text_similarity\n",
    "# from src.pimest import build_text_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquisition des données\n",
    "\n",
    "On récupère les données manuellement étiquetées et on les intègre dans un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 3) Processing PathGetter, total=   0.1s\n",
      "[Pipeline] ..... (step 2 of 3) Processing ContentGetter, total=   0.1s\n",
      "Launching 8 processes.\n",
      "[Pipeline] ..... (step 3 of 3) Processing ContentParser, total=  36.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>path</th>\n",
       "      <th>content</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a0492df6-9c76-4303-8813-65ec5ccbfa70</th>\n",
       "      <td>Concentré liquide Asian en bouteille 980 ml CHEF</td>\n",
       "      <td>Eau, maltodextrine, sel, arômes, sucre, arôme ...</td>\n",
       "      <td>../../ground_truth/a0492df6-9c76-4303-8813-65e...</td>\n",
       "      <td>b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>Concentré Liquide Asian CHEF® \\n\\nBouteille de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d183e914-db2f-4e2f-863a-a3b2d054c0b8</th>\n",
       "      <td>Pain burger curry 80 g CREATIV BURGER</td>\n",
       "      <td>Farine de blé T65, eau, levure, vinaigre de ci...</td>\n",
       "      <td>../../ground_truth/d183e914-db2f-4e2f-863a-a3b...</td>\n",
       "      <td>b'%PDF-1.5\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n4 0 obj\\r&lt;&lt;/L...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab48a1ed-7a3d-4686-bb6d-ab4f367cada8</th>\n",
       "      <td>Macaroni en sachet 500 g PANZANI</td>\n",
       "      <td>- 100% Semoule de BLE dur de qualité supérieur...</td>\n",
       "      <td>../../ground_truth/ab48a1ed-7a3d-4686-bb6d-ab4...</td>\n",
       "      <td>b'%PDF-1.4\\n%\\xc7\\xec\\x8f\\xa2\\n5 0 obj\\n&lt;&lt;/Len...</td>\n",
       "      <td>Direction Qualité \\n\\n \\n\\n \\n\\nPATES ALIMENTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e67341d8-350f-46f4-9154-4dbbb8035621</th>\n",
       "      <td>PRÉPARATION POUR CRÈME BRÛLÉE BIO 6L</td>\n",
       "      <td>Sucre roux de canne*° (64%), amidon de maïs*, ...</td>\n",
       "      <td>../../ground_truth/e67341d8-350f-46f4-9154-4db...</td>\n",
       "      <td>b'%PDF-1.7\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>FICHE TECHNIQUE \\n\\nCREME BRÛLÉE 6L \\n\\nREF : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3</th>\n",
       "      <td>Céréales instantanées en poudre saveur caramel...</td>\n",
       "      <td>Farine 87,1 % (Blé (GLUTEN), Blé hydrolysé (GL...</td>\n",
       "      <td>../../ground_truth/a8f6f672-20ac-4ff8-a8f2-3bc...</td>\n",
       "      <td>b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>81 rue de Sans Souci – CS13754 – 69576 Limones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0faad739-ea8c-4f03-b62e-51ee592a0546</th>\n",
       "      <td>FARINE DE BLÉ TYPE 45, 10KG</td>\n",
       "      <td>Farine de blé T45</td>\n",
       "      <td>../../ground_truth/0faad739-ea8c-4f03-b62e-51e...</td>\n",
       "      <td>b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>\\n1050/10502066400 \\n\\n10502055300/1050202520...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            designation  \\\n",
       "uid                                                                                       \n",
       "a0492df6-9c76-4303-8813-65ec5ccbfa70   Concentré liquide Asian en bouteille 980 ml CHEF   \n",
       "d183e914-db2f-4e2f-863a-a3b2d054c0b8              Pain burger curry 80 g CREATIV BURGER   \n",
       "ab48a1ed-7a3d-4686-bb6d-ab4f367cada8                   Macaroni en sachet 500 g PANZANI   \n",
       "...                                                                                 ...   \n",
       "e67341d8-350f-46f4-9154-4dbbb8035621               PRÉPARATION POUR CRÈME BRÛLÉE BIO 6L   \n",
       "a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3  Céréales instantanées en poudre saveur caramel...   \n",
       "0faad739-ea8c-4f03-b62e-51ee592a0546                        FARINE DE BLÉ TYPE 45, 10KG   \n",
       "\n",
       "                                                                            ingredients  \\\n",
       "uid                                                                                       \n",
       "a0492df6-9c76-4303-8813-65ec5ccbfa70  Eau, maltodextrine, sel, arômes, sucre, arôme ...   \n",
       "d183e914-db2f-4e2f-863a-a3b2d054c0b8  Farine de blé T65, eau, levure, vinaigre de ci...   \n",
       "ab48a1ed-7a3d-4686-bb6d-ab4f367cada8  - 100% Semoule de BLE dur de qualité supérieur...   \n",
       "...                                                                                 ...   \n",
       "e67341d8-350f-46f4-9154-4dbbb8035621  Sucre roux de canne*° (64%), amidon de maïs*, ...   \n",
       "a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3  Farine 87,1 % (Blé (GLUTEN), Blé hydrolysé (GL...   \n",
       "0faad739-ea8c-4f03-b62e-51ee592a0546                                  Farine de blé T45   \n",
       "\n",
       "                                                                                   path  \\\n",
       "uid                                                                                       \n",
       "a0492df6-9c76-4303-8813-65ec5ccbfa70  ../../ground_truth/a0492df6-9c76-4303-8813-65e...   \n",
       "d183e914-db2f-4e2f-863a-a3b2d054c0b8  ../../ground_truth/d183e914-db2f-4e2f-863a-a3b...   \n",
       "ab48a1ed-7a3d-4686-bb6d-ab4f367cada8  ../../ground_truth/ab48a1ed-7a3d-4686-bb6d-ab4...   \n",
       "...                                                                                 ...   \n",
       "e67341d8-350f-46f4-9154-4dbbb8035621  ../../ground_truth/e67341d8-350f-46f4-9154-4db...   \n",
       "a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3  ../../ground_truth/a8f6f672-20ac-4ff8-a8f2-3bc...   \n",
       "0faad739-ea8c-4f03-b62e-51ee592a0546  ../../ground_truth/0faad739-ea8c-4f03-b62e-51e...   \n",
       "\n",
       "                                                                                content  \\\n",
       "uid                                                                                       \n",
       "a0492df6-9c76-4303-8813-65ec5ccbfa70  b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...   \n",
       "d183e914-db2f-4e2f-863a-a3b2d054c0b8  b'%PDF-1.5\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n4 0 obj\\r<</L...   \n",
       "ab48a1ed-7a3d-4686-bb6d-ab4f367cada8  b'%PDF-1.4\\n%\\xc7\\xec\\x8f\\xa2\\n5 0 obj\\n<</Len...   \n",
       "...                                                                                 ...   \n",
       "e67341d8-350f-46f4-9154-4dbbb8035621  b'%PDF-1.7\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...   \n",
       "a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3  b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...   \n",
       "0faad739-ea8c-4f03-b62e-51ee592a0546  b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...   \n",
       "\n",
       "                                                                                   text  \n",
       "uid                                                                                      \n",
       "a0492df6-9c76-4303-8813-65ec5ccbfa70  Concentré Liquide Asian CHEF® \\n\\nBouteille de...  \n",
       "d183e914-db2f-4e2f-863a-a3b2d054c0b8                                                  \n",
       "  \n",
       "ab48a1ed-7a3d-4686-bb6d-ab4f367cada8  Direction Qualité \\n\\n \\n\\n \\n\\nPATES ALIMENTA...  \n",
       "...                                                                                 ...  \n",
       "e67341d8-350f-46f4-9154-4dbbb8035621  FICHE TECHNIQUE \\n\\nCREME BRÛLÉE 6L \\n\\nREF : ...  \n",
       "a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3  81 rue de Sans Souci – CS13754 – 69576 Limones...  \n",
       "0faad739-ea8c-4f03-b62e-51ee592a0546   \\n1050/10502066400 \\n\\n10502055300/1050202520...  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_df = pd.read_csv(Path('..') / '..' / 'ground_truth' / 'manually_labelled_ground_truth.csv',\n",
    "                              sep=';',\n",
    "                              encoding='latin-1',\n",
    "                              index_col='uid')\n",
    "ground_truth_uids = list(ground_truth_df.index)\n",
    "\n",
    "acqui_pipe = Pipeline([('PathGetter', PathGetter(ground_truth_uids=ground_truth_uids,\n",
    "                                                  train_set_path=Path('..') / '..' / 'ground_truth',\n",
    "                                                  ground_truth_path=Path('..') / '..' / 'ground_truth',\n",
    "                                                  )),\n",
    "                        ('ContentGetter', ContentGetter(missing_file='to_nan')),\n",
    "                        ('ContentParser', PDFContentParser(none_content='to_empty')),\n",
    "                       ],\n",
    "                       verbose=True)\n",
    "\n",
    "texts_df = acqui_pipe.fit_transform(ground_truth_df)\n",
    "texts_df['ingredients'] = texts_df['ingredients'].fillna('')\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test split\n",
    "\n",
    "On va appliquer une grid search pour déterminer les meilleurs paramètres de notre modèle. \n",
    "Pour ne pas surestimer la performance du modèle, il est nécessaire de bien séparer le jeu de test du jeu d'entraînement, y compris pour la grid search !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(texts_df, test_size=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans toute la suite, on utilisera le jeu d'entraînement pour effectuer le tuning des hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustement de la fonction de découpage des textes\n",
    "\n",
    "L'objectif de cette partie est d'optimiser la fonction de découpage des textes en blocs. On va tester quelques fonctions candidates, via une GridSearch.\n",
    "\n",
    "### Définition des fonctions candidates\n",
    "\n",
    "On définit les fonctions de split : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions of splitter funcs\n",
    "splitter_funcs = []\n",
    "def split_func(text):\n",
    "    return(text.split('\\n\\n'))\n",
    "splitter_funcs.append(split_func)\n",
    "def split_func(text):\n",
    "    return(text.split('\\n'))\n",
    "splitter_funcs.append(split_func)\n",
    "def split_func(text):\n",
    "    regex = r'\\s*\\n\\s*\\n\\s*'\n",
    "    return(re.split(regex, text))\n",
    "splitter_funcs.append(split_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place du pipeline\n",
    "\n",
    "On construit ensuite un pipeline de traitement du texte.\n",
    "Le SimilaritySelector prenant en entrée une pandas.Series, on définit entre le BlockSplitter (dont la méthode transform() retourne un pandas.DataFrame) et le SimilaritySelector une fonction utilitaire qui séléctionne la colonne 'blocks'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_col(df, col_name='blocks'):\n",
    "        return(df[col_name].fillna(''))\n",
    "col_selector = FunctionTransformer(select_col)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_pipe = Pipeline([('Splitter', BlockSplitter()),\n",
    "                         ('ColumnSelector', col_selector),\n",
    "                         ('SimilaritySelector', SimilaritySelector())\n",
    "                        ],\n",
    "                       verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut tester le fonctionnement de ce Pipeline.\n",
    "Attention, les résultats ne sont pas représentatifs, on entraîne et on prédit sur le même jeu de données !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 8 processes.\n",
      "Launching 8 processes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "uid\n",
       "02d5ceb9-21c2-4965-8f65-309bca7638b2    Café chicorée solubles et fibres de chicorée.\\...\n",
       "bbe72396-6ed4-4df1-935b-0c0a7dbd77dc                                                     \n",
       "507b428e-e99d-464b-b9d3-50629efe4355    COMPOSITION\\nMélange de Blés de pays recommand...\n",
       "                                                              ...                        \n",
       "4b28bb17-1f1d-4cbb-ac3b-80227ef248ab    Gluten\\nCrustacés\\nOeufs\\nPoisson\\nSoja\\nLait\\...\n",
       "d2137dae-ff21-46ec-83be-7400773c6c3b    Amidon modifié de pomme de terre - Fécule de p...\n",
       "571d98ae-9647-4bd4-ad1a-a497f93987cb    Composition typique (Données inappropriées pou...\n",
       "Length: 400, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_pipe.fit(train, train['ingredients'])\n",
    "process_pipe.predict(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application de la GridSearch\n",
    "\n",
    "On applique ensuite une grid search en faisant varier les fonctions de split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('Splitter', <src.pimest.BlockSplitter at 0x7f250c6b6cd0>),\n",
       "  ('ColumnSelector',\n",
       "   FunctionTransformer(func=<function select_col at 0x7f252a0d5dc0>)),\n",
       "  ('SimilaritySelector', <src.pimest.SimilaritySelector at 0x7f250c6b6bb0>)],\n",
       " 'verbose': False,\n",
       " 'Splitter': <src.pimest.BlockSplitter at 0x7f250c6b6cd0>,\n",
       " 'ColumnSelector': FunctionTransformer(func=<function select_col at 0x7f252a0d5dc0>),\n",
       " 'SimilaritySelector': <src.pimest.SimilaritySelector at 0x7f250c6b6bb0>,\n",
       " 'Splitter__source_col': 'text',\n",
       " 'Splitter__target_col': 'blocks',\n",
       " 'Splitter__target_exists': 'raise',\n",
       " 'Splitter__splitter_func': <function src.pimest.BlockSplitter.<lambda>(x)>,\n",
       " 'ColumnSelector__accept_sparse': False,\n",
       " 'ColumnSelector__check_inverse': True,\n",
       " 'ColumnSelector__func': <function __main__.select_col(df, col_name='blocks')>,\n",
       " 'ColumnSelector__inv_kw_args': None,\n",
       " 'ColumnSelector__inverse_func': None,\n",
       " 'ColumnSelector__kw_args': None,\n",
       " 'ColumnSelector__validate': False,\n",
       " 'SimilaritySelector__count_vect_kwargs': {'norm': None, 'use_idf': False},\n",
       " 'SimilaritySelector__similarity': 'projection',\n",
       " 'SimilaritySelector__source_norm': 'l2',\n",
       " 'SimilaritySelector__projected_norm': 'l1'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_scorer = partial(text_sim_score, similarity='levenshtein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {'pas', 'le', 'en', 'pour', 'ou', 'ce', 'de', 'dans', 'du', 'and', 'un', 'sur', 'et',\n",
    "              'of', 'est', 'par', 'la', 'les', 'dont', 'au', 'des', 'que'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 8 processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   35.5s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'Splitter__splitter_func': splitter_funcs,\n",
    "               'SimilaritySelector__similarity': ['projection', 'cosine'],\n",
    "               'SimilaritySelector__count_vect_kwargs': [{'stop_words': stop_words},\n",
    "                                                         {'stop_words': None},\n",
    "                                                        ],\n",
    "              }\n",
    "             ]\n",
    "search = GridSearchCV(process_pipe,\n",
    "                      param_grid,\n",
    "                      cv=10, \n",
    "                      scoring= lev_scorer,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1,\n",
    "                     ).fit(train, train['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.5242799 , 0.29072883, 0.20813572, 0.19394908, 0.232284  ,\n",
       "        0.20478857, 0.2006624 , 0.2214685 , 0.20743845, 0.20030537,\n",
       "        0.2202004 , 0.20550847]),\n",
       " 'std_fit_time': array([0.10931549, 0.07337048, 0.00735431, 0.00745012, 0.01088503,\n",
       "        0.00518096, 0.00743987, 0.00959173, 0.00558991, 0.01060589,\n",
       "        0.01137143, 0.00863639]),\n",
       " 'mean_score_time': array([0.37875197, 0.2663589 , 0.19132805, 0.1705699 , 0.24689152,\n",
       "        0.16716609, 0.18274245, 0.21833038, 0.18290744, 0.16947865,\n",
       "        0.23152869, 0.16484597]),\n",
       " 'std_score_time': array([0.06868515, 0.04970968, 0.02122265, 0.00945115, 0.01963565,\n",
       "        0.01001417, 0.00642451, 0.01058498, 0.00990497, 0.01345436,\n",
       "        0.0162835 , 0.00923047]),\n",
       " 'param_SimilaritySelector__count_vect_kwargs': masked_array(data=[{'stop_words': {'en', 'un', 'of', 'pour', 'le', 'ce', 'du', 'dont', 'dans', 'par', 'les', 'et', 'au', 'de', 'la', 'que', 'des', 'sur', 'pas', 'and', 'ou', 'est'}},\n",
       "                    {'stop_words': {'en', 'un', 'of', 'pour', 'le', 'ce', 'du', 'dont', 'dans', 'par', 'les', 'et', 'au', 'de', 'la', 'que', 'des', 'sur', 'pas', 'and', 'ou', 'est'}},\n",
       "                    {'stop_words': {'en', 'un', 'of', 'pour', 'le', 'ce', 'du', 'dont', 'dans', 'par', 'les', 'et', 'au', 'de', 'la', 'que', 'des', 'sur', 'pas', 'and', 'ou', 'est'}},\n",
       "                    {'stop_words': {'en', 'un', 'of', 'pour', 'le', 'ce', 'du', 'dont', 'dans', 'par', 'les', 'et', 'au', 'de', 'la', 'que', 'des', 'sur', 'pas', 'and', 'ou', 'est'}},\n",
       "                    {'stop_words': {'en', 'un', 'of', 'pour', 'le', 'ce', 'du', 'dont', 'dans', 'par', 'les', 'et', 'au', 'de', 'la', 'que', 'des', 'sur', 'pas', 'and', 'ou', 'est'}},\n",
       "                    {'stop_words': {'en', 'un', 'of', 'pour', 'le', 'ce', 'du', 'dont', 'dans', 'par', 'les', 'et', 'au', 'de', 'la', 'que', 'des', 'sur', 'pas', 'and', 'ou', 'est'}},\n",
       "                    {'stop_words': None}, {'stop_words': None},\n",
       "                    {'stop_words': None}, {'stop_words': None},\n",
       "                    {'stop_words': None}, {'stop_words': None}],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_SimilaritySelector__similarity': masked_array(data=['projection', 'projection', 'projection', 'cosine',\n",
       "                    'cosine', 'cosine', 'projection', 'projection',\n",
       "                    'projection', 'cosine', 'cosine', 'cosine'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_Splitter__splitter_func': masked_array(data=[<function split_func at 0x7f252a0d5af0>,\n",
       "                    <function split_func at 0x7f252a0d5940>,\n",
       "                    <function split_func at 0x7f252a0d59d0>,\n",
       "                    <function split_func at 0x7f252a0d5af0>,\n",
       "                    <function split_func at 0x7f252a0d5940>,\n",
       "                    <function split_func at 0x7f252a0d59d0>,\n",
       "                    <function split_func at 0x7f252a0d5af0>,\n",
       "                    <function split_func at 0x7f252a0d5940>,\n",
       "                    <function split_func at 0x7f252a0d59d0>,\n",
       "                    <function split_func at 0x7f252a0d5af0>,\n",
       "                    <function split_func at 0x7f252a0d5940>,\n",
       "                    <function split_func at 0x7f252a0d59d0>],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'}},\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'}},\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'}},\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'}},\n",
       "   'SimilaritySelector__similarity': 'cosine',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'}},\n",
       "   'SimilaritySelector__similarity': 'cosine',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'}},\n",
       "   'SimilaritySelector__similarity': 'cosine',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': None},\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': None},\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': None},\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': None},\n",
       "   'SimilaritySelector__similarity': 'cosine',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': None},\n",
       "   'SimilaritySelector__similarity': 'cosine',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': None},\n",
       "   'SimilaritySelector__similarity': 'cosine',\n",
       "   'Splitter__splitter_func': <function __main__.split_func(text)>}],\n",
       " 'split0_test_score': array([0.53113406, 0.40822346, 0.556359  , 0.40491749, 0.23037603,\n",
       "        0.42816333, 0.50405873, 0.38747049, 0.52675676, 0.38290894,\n",
       "        0.25311754, 0.39999935]),\n",
       " 'split1_test_score': array([0.53348406, 0.4113191 , 0.56913918, 0.5363397 , 0.35072403,\n",
       "        0.57327887, 0.50186314, 0.40089462, 0.53751827, 0.45084889,\n",
       "        0.26452805, 0.46533639]),\n",
       " 'split2_test_score': array([0.58587489, 0.3323346 , 0.63149342, 0.55161211, 0.19911316,\n",
       "        0.61397393, 0.53912288, 0.32540593, 0.57583562, 0.44381288,\n",
       "        0.21778938, 0.45711491]),\n",
       " 'split3_test_score': array([0.48734916, 0.42816548, 0.48773666, 0.43988352, 0.26951603,\n",
       "        0.42321685, 0.38014793, 0.32741489, 0.38733704, 0.38397116,\n",
       "        0.27779029, 0.3863057 ]),\n",
       " 'split4_test_score': array([0.54971424, 0.37219804, 0.5627768 , 0.5177562 , 0.29197415,\n",
       "        0.5177562 , 0.52922376, 0.33604936, 0.52922376, 0.42963741,\n",
       "        0.25347315, 0.42963741]),\n",
       " 'split5_test_score': array([0.64992487, 0.4766314 , 0.71856626, 0.62809322, 0.38203817,\n",
       "        0.68078211, 0.62547778, 0.46342008, 0.67562222, 0.47291938,\n",
       "        0.30327048, 0.50453685]),\n",
       " 'split6_test_score': array([0.52431645, 0.44894864, 0.5587964 , 0.47611265, 0.34708336,\n",
       "        0.49221868, 0.49978524, 0.42474546, 0.52555514, 0.34127887,\n",
       "        0.27771723, 0.36629493]),\n",
       " 'split7_test_score': array([0.49158031, 0.43235804, 0.54815586, 0.48376613, 0.30130313,\n",
       "        0.54905085, 0.46401599, 0.38816519, 0.50886715, 0.3598654 ,\n",
       "        0.28156836, 0.40967951]),\n",
       " 'split8_test_score': array([0.55841852, 0.44208857, 0.57797373, 0.52208601, 0.24433231,\n",
       "        0.51482157, 0.46190696, 0.39424024, 0.49026037, 0.37456124,\n",
       "        0.22959005, 0.35475855]),\n",
       " 'split9_test_score': array([0.56205346, 0.40013972, 0.57312795, 0.5278685 , 0.31725363,\n",
       "        0.52700412, 0.47503823, 0.37640682, 0.49935041, 0.46319186,\n",
       "        0.26696766, 0.49732418]),\n",
       " 'mean_test_score': array([0.547385  , 0.41524071, 0.57841253, 0.50884355, 0.2933714 ,\n",
       "        0.53202665, 0.49806406, 0.38242131, 0.52563267, 0.4102996 ,\n",
       "        0.26258122, 0.42709878]),\n",
       " 'std_test_score': array([0.04477296, 0.03886471, 0.0572957 , 0.05888864, 0.05522523,\n",
       "        0.07454652, 0.05987099, 0.04165881, 0.06820656, 0.0445963 ,\n",
       "        0.0240142 , 0.04992984]),\n",
       " 'rank_test_score': array([ 2,  8,  1,  5, 11,  3,  6, 10,  4,  9, 12,  7], dtype=int32)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que la fonction de split la plus efficace est la fonction qui applique la regex (deux retours chariots parmi des whitespaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Avec stopwords, Projection l2/l1, Split 1 54.74% +/- 4.48%\n",
      "Avec stopwords, Projection l2/l1, Split 2 41.52% +/- 3.89%\n",
      "Avec stopwords, Projection l2/l1, Split 3 57.84% +/- 5.73%\n",
      "Avec stopwords, Cosinus, Split 1 50.88% +/- 5.89%\n",
      "Avec stopwords, Cosinus, Split 2 29.34% +/- 5.52%\n",
      "Avec stopwords, Cosinus, Split 3 53.20% +/- 7.45%\n",
      "Sans stopwords, Projection l2/l1, Split 1 49.81% +/- 5.99%\n",
      "Sans stopwords, Projection l2/l1, Split 2 38.24% +/- 4.17%\n",
      "Sans stopwords, Projection l2/l1, Split 3 52.56% +/- 6.82%\n",
      "Sans stopwords, Cosinus, Split 1 41.03% +/- 4.46%\n",
      "Sans stopwords, Cosinus, Split 2 26.26% +/- 2.40%\n",
      "Sans stopwords, Cosinus, Split 3 42.71% +/- 4.99%\n"
     ]
    }
   ],
   "source": [
    "labels = list(product(['Avec stopwords', 'Sans stopwords'],\n",
    "                      ['Projection l2/l1', 'Cosinus'],\n",
    "                      ['Split 1', 'Split 2', 'Split 3'], \n",
    "                 ))\n",
    "\n",
    "for i in range(len(search.cv_results_['rank_test_score'])):\n",
    "    str_result = f\"{search.cv_results_['mean_test_score'][i]:.2%} +/- {search.cv_results_['std_test_score'][i]:.2%}\"\n",
    "    print(', '.join(labels[i]), str_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
