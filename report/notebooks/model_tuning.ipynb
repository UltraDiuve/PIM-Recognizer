{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning du modèle\n",
    "\n",
    "L'objet de ce notebook est d'illustrer les différentes étapes de tuning du modèle.\n",
    "\n",
    "\n",
    "## Préambule\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up sys.path for relative imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = str(Path(sys.path[0]).parents[1].absolute())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and customization of diplay\n",
    "# import os\n",
    "import re\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.min_rows = 6\n",
    "pd.options.display.width=108\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "from src.pimest import ContentGetter\n",
    "from src.pimest import PathGetter\n",
    "from src.pimest import PDFContentParser\n",
    "from src.pimest import BlockSplitter\n",
    "from src.pimest import SimilaritySelector\n",
    "# from src.pimest import custom_accuracy\n",
    "from src.pimest import text_sim_score\n",
    "# from src.pimest import text_similarity\n",
    "# from src.pimest import build_text_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquisition des données\n",
    "\n",
    "On récupère les données manuellement étiquetées et on les intègre dans un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 3) Processing PathGetter, total=   0.1s\n",
      "[Pipeline] ..... (step 2 of 3) Processing ContentGetter, total=   0.6s\n",
      "Launching 8 processes.\n",
      "[Pipeline] ..... (step 3 of 3) Processing ContentParser, total=  36.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>path</th>\n",
       "      <th>content</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a0492df6-9c76-4303-8813-65ec5ccbfa70</th>\n",
       "      <td>Concentré liquide Asian en bouteille 980 ml CHEF</td>\n",
       "      <td>Eau, maltodextrine, sel, arômes, sucre, arôme ...</td>\n",
       "      <td>../../ground_truth/a0492df6-9c76-4303-8813-65e...</td>\n",
       "      <td>b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>Concentré Liquide Asian CHEF® \\n\\nBouteille de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d183e914-db2f-4e2f-863a-a3b2d054c0b8</th>\n",
       "      <td>Pain burger curry 80 g CREATIV BURGER</td>\n",
       "      <td>Farine de blé T65, eau, levure, vinaigre de ci...</td>\n",
       "      <td>../../ground_truth/d183e914-db2f-4e2f-863a-a3b...</td>\n",
       "      <td>b'%PDF-1.5\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n4 0 obj\\r&lt;&lt;/L...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab48a1ed-7a3d-4686-bb6d-ab4f367cada8</th>\n",
       "      <td>Macaroni en sachet 500 g PANZANI</td>\n",
       "      <td>- 100% Semoule de BLE dur de qualité supérieur...</td>\n",
       "      <td>../../ground_truth/ab48a1ed-7a3d-4686-bb6d-ab4...</td>\n",
       "      <td>b'%PDF-1.4\\n%\\xc7\\xec\\x8f\\xa2\\n5 0 obj\\n&lt;&lt;/Len...</td>\n",
       "      <td>Direction Qualité \\n\\n \\n\\n \\n\\nPATES ALIMENTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e67341d8-350f-46f4-9154-4dbbb8035621</th>\n",
       "      <td>PRÉPARATION POUR CRÈME BRÛLÉE BIO 6L</td>\n",
       "      <td>Sucre roux de canne*° (64%), amidon de maïs*, ...</td>\n",
       "      <td>../../ground_truth/e67341d8-350f-46f4-9154-4db...</td>\n",
       "      <td>b'%PDF-1.7\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>FICHE TECHNIQUE \\n\\nCREME BRÛLÉE 6L \\n\\nREF : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3</th>\n",
       "      <td>Céréales instantanées en poudre saveur caramel...</td>\n",
       "      <td>Farine 87,1 % (Blé (GLUTEN), Blé hydrolysé (GL...</td>\n",
       "      <td>../../ground_truth/a8f6f672-20ac-4ff8-a8f2-3bc...</td>\n",
       "      <td>b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>81 rue de Sans Souci – CS13754 – 69576 Limones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0faad739-ea8c-4f03-b62e-51ee592a0546</th>\n",
       "      <td>FARINE DE BLÉ TYPE 45, 10KG</td>\n",
       "      <td>Farine de blé T45</td>\n",
       "      <td>../../ground_truth/0faad739-ea8c-4f03-b62e-51e...</td>\n",
       "      <td>b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>\\n1050/10502066400 \\n\\n10502055300/1050202520...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            designation  \\\n",
       "uid                                                                                       \n",
       "a0492df6-9c76-4303-8813-65ec5ccbfa70   Concentré liquide Asian en bouteille 980 ml CHEF   \n",
       "d183e914-db2f-4e2f-863a-a3b2d054c0b8              Pain burger curry 80 g CREATIV BURGER   \n",
       "ab48a1ed-7a3d-4686-bb6d-ab4f367cada8                   Macaroni en sachet 500 g PANZANI   \n",
       "...                                                                                 ...   \n",
       "e67341d8-350f-46f4-9154-4dbbb8035621               PRÉPARATION POUR CRÈME BRÛLÉE BIO 6L   \n",
       "a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3  Céréales instantanées en poudre saveur caramel...   \n",
       "0faad739-ea8c-4f03-b62e-51ee592a0546                        FARINE DE BLÉ TYPE 45, 10KG   \n",
       "\n",
       "                                                                            ingredients  \\\n",
       "uid                                                                                       \n",
       "a0492df6-9c76-4303-8813-65ec5ccbfa70  Eau, maltodextrine, sel, arômes, sucre, arôme ...   \n",
       "d183e914-db2f-4e2f-863a-a3b2d054c0b8  Farine de blé T65, eau, levure, vinaigre de ci...   \n",
       "ab48a1ed-7a3d-4686-bb6d-ab4f367cada8  - 100% Semoule de BLE dur de qualité supérieur...   \n",
       "...                                                                                 ...   \n",
       "e67341d8-350f-46f4-9154-4dbbb8035621  Sucre roux de canne*° (64%), amidon de maïs*, ...   \n",
       "a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3  Farine 87,1 % (Blé (GLUTEN), Blé hydrolysé (GL...   \n",
       "0faad739-ea8c-4f03-b62e-51ee592a0546                                  Farine de blé T45   \n",
       "\n",
       "                                                                                   path  \\\n",
       "uid                                                                                       \n",
       "a0492df6-9c76-4303-8813-65ec5ccbfa70  ../../ground_truth/a0492df6-9c76-4303-8813-65e...   \n",
       "d183e914-db2f-4e2f-863a-a3b2d054c0b8  ../../ground_truth/d183e914-db2f-4e2f-863a-a3b...   \n",
       "ab48a1ed-7a3d-4686-bb6d-ab4f367cada8  ../../ground_truth/ab48a1ed-7a3d-4686-bb6d-ab4...   \n",
       "...                                                                                 ...   \n",
       "e67341d8-350f-46f4-9154-4dbbb8035621  ../../ground_truth/e67341d8-350f-46f4-9154-4db...   \n",
       "a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3  ../../ground_truth/a8f6f672-20ac-4ff8-a8f2-3bc...   \n",
       "0faad739-ea8c-4f03-b62e-51ee592a0546  ../../ground_truth/0faad739-ea8c-4f03-b62e-51e...   \n",
       "\n",
       "                                                                                content  \\\n",
       "uid                                                                                       \n",
       "a0492df6-9c76-4303-8813-65ec5ccbfa70  b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...   \n",
       "d183e914-db2f-4e2f-863a-a3b2d054c0b8  b'%PDF-1.5\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n4 0 obj\\r<</L...   \n",
       "ab48a1ed-7a3d-4686-bb6d-ab4f367cada8  b'%PDF-1.4\\n%\\xc7\\xec\\x8f\\xa2\\n5 0 obj\\n<</Len...   \n",
       "...                                                                                 ...   \n",
       "e67341d8-350f-46f4-9154-4dbbb8035621  b'%PDF-1.7\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...   \n",
       "a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3  b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...   \n",
       "0faad739-ea8c-4f03-b62e-51ee592a0546  b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...   \n",
       "\n",
       "                                                                                   text  \n",
       "uid                                                                                      \n",
       "a0492df6-9c76-4303-8813-65ec5ccbfa70  Concentré Liquide Asian CHEF® \\n\\nBouteille de...  \n",
       "d183e914-db2f-4e2f-863a-a3b2d054c0b8                                                  \n",
       "  \n",
       "ab48a1ed-7a3d-4686-bb6d-ab4f367cada8  Direction Qualité \\n\\n \\n\\n \\n\\nPATES ALIMENTA...  \n",
       "...                                                                                 ...  \n",
       "e67341d8-350f-46f4-9154-4dbbb8035621  FICHE TECHNIQUE \\n\\nCREME BRÛLÉE 6L \\n\\nREF : ...  \n",
       "a8f6f672-20ac-4ff8-a8f2-3bc4306c8df3  81 rue de Sans Souci – CS13754 – 69576 Limones...  \n",
       "0faad739-ea8c-4f03-b62e-51ee592a0546   \\n1050/10502066400 \\n\\n10502055300/1050202520...  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_df = pd.read_csv(Path('..') / '..' / 'ground_truth' / 'manually_labelled_ground_truth.csv',\n",
    "                              sep=';',\n",
    "                              encoding='latin-1',\n",
    "                              index_col='uid')\n",
    "ground_truth_uids = list(ground_truth_df.index)\n",
    "\n",
    "acqui_pipe = Pipeline([('PathGetter', PathGetter(ground_truth_uids=ground_truth_uids,\n",
    "                                                  train_set_path=Path('..') / '..' / 'ground_truth',\n",
    "                                                  ground_truth_path=Path('..') / '..' / 'ground_truth',\n",
    "                                                  )),\n",
    "                        ('ContentGetter', ContentGetter(missing_file='to_nan')),\n",
    "                        ('ContentParser', PDFContentParser(none_content='to_empty')),\n",
    "                       ],\n",
    "                       verbose=True)\n",
    "\n",
    "texts_df = acqui_pipe.fit_transform(ground_truth_df)\n",
    "texts_df['ingredients'] = texts_df['ingredients'].fillna('')\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test split\n",
    "\n",
    "On va appliquer une grid search pour déterminer les meilleurs paramètres de notre modèle. \n",
    "Pour ne pas surestimer la performance du modèle, il est nécessaire de bien séparer le jeu de test du jeu d'entraînement, y compris pour la grid search !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(texts_df, test_size=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans toute la suite, on utilisera le jeu d'entraînement pour effectuer le tuning des hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustement de la fonction de découpage des textes\n",
    "\n",
    "L'objectif de cette partie est d'optimiser la fonction de découpage des textes en blocs. On va tester quelques fonctions candidates, via une GridSearch.\n",
    "\n",
    "### Définition des fonctions candidates\n",
    "\n",
    "On définit les fonctions de split : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions of splitter funcs\n",
    "splitter_funcs = []\n",
    "def split_func(text):\n",
    "    return(text.split('\\n\\n'))\n",
    "splitter_funcs.append(split_func)\n",
    "def split_func(text):\n",
    "    return(text.split('\\n'))\n",
    "splitter_funcs.append(split_func)\n",
    "def split_func(text):\n",
    "    regex = r'\\s*\\n\\s*\\n\\s*'\n",
    "    return(re.split(regex, text))\n",
    "splitter_funcs.append(split_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place du pipeline\n",
    "\n",
    "On construit ensuite un pipeline de traitement du texte.\n",
    "Le SimilaritySelector prenant en entrée une pandas.Series, on définit entre le BlockSplitter (dont la méthode transform() retourne un pandas.DataFrame) et le SimilaritySelector une fonction utilitaire qui séléctionne la colonne 'blocks'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_col(df, col_name='blocks'):\n",
    "        return(df[col_name].fillna(''))\n",
    "col_selector = FunctionTransformer(select_col)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_pipe = Pipeline([('Splitter', BlockSplitter()),\n",
    "                         ('ColumnSelector', col_selector),\n",
    "                         ('SimilaritySelector', SimilaritySelector())\n",
    "                        ],\n",
    "                       verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut tester le fonctionnement de ce Pipeline.\n",
    "Attention, les résultats ne sont pas représentatifs, on entraîne et on prédit sur le même jeu de données !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 8 processes.\n",
      "Launching 8 processes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "uid\n",
       "02d5ceb9-21c2-4965-8f65-309bca7638b2    Café chicorée solubles et fibres de chicorée.\\...\n",
       "bbe72396-6ed4-4df1-935b-0c0a7dbd77dc                                                     \n",
       "507b428e-e99d-464b-b9d3-50629efe4355    COMPOSITION\\nMélange de Blés de pays recommand...\n",
       "                                                              ...                        \n",
       "4b28bb17-1f1d-4cbb-ac3b-80227ef248ab    Gluten\\nCrustacés\\nOeufs\\nPoisson\\nSoja\\nLait\\...\n",
       "d2137dae-ff21-46ec-83be-7400773c6c3b    Amidon modifié de pomme de terre - Fécule de p...\n",
       "571d98ae-9647-4bd4-ad1a-a497f93987cb    Composition typique (Données inappropriées pou...\n",
       "Length: 400, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_pipe.fit(train, train['ingredients'])\n",
    "process_pipe.predict(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper fonction\n",
    "\n",
    "On doit faire varier dans la grid search des paramètres qui sont packés sous forme de dictionnaires avant d'être passés au SimilaritySelector.\n",
    "On construit une fonction qui permet de construire le produit cartésien qui va bien pour ces paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_params(dict_to_prod):\n",
    "    \"\"\" \n",
    "    In : dict of dicts.\n",
    "    First level key : parameter name\n",
    "    Second level key : name of scenario with this parameter value\n",
    "    Values : parameter value\n",
    "    \n",
    "    Returns a tuple: \n",
    "        - list of labels to name scenario\n",
    "        - list of dictionaries to pass to count_vect_kwargs\n",
    "    \"\"\"\n",
    "    label_lists = [list(dict_.keys()) for dict_ in dict_to_prod.values()]\n",
    "    labels = list(map(lambda x: ', '.join(x), list(product(*label_lists))))\n",
    "    values_iter = list(product(*[list(dict_.values()) for dict_ in dict_to_prod.values()]))\n",
    "    parms_names = list(dict_to_prod.keys())\n",
    "    dict_out = [{key: val for (key, val) in zip(parms_names, values_)} for values_ in values_iter]\n",
    "    return(labels, dict_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['no stopwords removal, no_ngram',\n",
       "  'no stopwords removal, bigrams',\n",
       "  'with stopwords removal, no_ngram',\n",
       "  'with stopwords removal, bigrams'],\n",
       " [{'stop_words': None, 'ngram_ranges': (1, 1)},\n",
       "  {'stop_words': None, 'ngram_ranges': (1, 2)},\n",
       "  {'stop_words': {'de', 'le'}, 'ngram_ranges': (1, 1)},\n",
       "  {'stop_words': {'de', 'le'}, 'ngram_ranges': (1, 2)}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_params({'stop_words': {'no stopwords removal': None, 'with stopwords removal' : {'de', 'le'}},\n",
    "             'ngram_ranges': {'no_ngram': (1, 1), 'bigrams': (1, 2)}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application de la GridSearch : tuning du text_preprocessing\n",
    "\n",
    "On applique ensuite une grid search en faisant varier les fonctions de text preprocessing : \n",
    "- fonction de split du texte des documents en blocs\n",
    "- retrait ou non de stopwords\n",
    "- prise en compte de ngrams\n",
    "- juste pour une première comparaison, choix du candidat par projection l1/l2 ou par similarité cosinus\n",
    "\n",
    "On scorera via la similarité de Levenshtein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_scorer = partial(text_sim_score, similarity='levenshtein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {'pas', 'le', 'en', 'pour', 'ou', 'ce', 'de', 'dans', 'du', 'and', 'un', 'sur', 'et',\n",
    "              'of', 'est', 'par', 'la', 'les', 'dont', 'au', 'des', 'que'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_ranges = {'no_ngram': (1, 1), 'bigrams': (1, 2), 'trigrams': (1, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_to_prod = prod_params({'stop_words': {'no stopwords removal': None, 'with stopwords removal' : stop_words},\n",
    "                              'ngram_range': ngram_ranges,\n",
    "                              'strip_accents': {'keep accents': None, 'remove accents': 'unicode'}\n",
    "                             }\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 72 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 8 processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 576 out of 576 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'Splitter__splitter_func': splitter_funcs,\n",
    "               'SimilaritySelector__similarity': ['projection', 'cosine'],\n",
    "               'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "              }\n",
    "             ]\n",
    "search = GridSearchCV(process_pipe,\n",
    "                      param_grid,\n",
    "                      cv=8, \n",
    "                      scoring= lev_scorer,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1,\n",
    "                     ).fit(train, train['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(product(kwargs_to_prod[0], ['Projection l2/l1', 'Cosinus'], ['Split 1', 'Split 2', 'Split 3']))\n",
    "labels = list(map(lambda x: ', '.join(x), labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "   'au',\n",
       "   'ce',\n",
       "   'dans',\n",
       "   'de',\n",
       "   'des',\n",
       "   'dont',\n",
       "   'du',\n",
       "   'en',\n",
       "   'est',\n",
       "   'et',\n",
       "   'la',\n",
       "   'le',\n",
       "   'les',\n",
       "   'of',\n",
       "   'ou',\n",
       "   'par',\n",
       "   'pas',\n",
       "   'pour',\n",
       "   'que',\n",
       "   'sur',\n",
       "   'un'},\n",
       "  'ngram_range': (1, 3),\n",
       "  'strip_accents': 'unicode'},\n",
       " 'SimilaritySelector__similarity': 'projection',\n",
       " 'Splitter__splitter_func': <function __main__.split_func(text)>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stopwords removal, no_ngram, keep accents, Projection l2/l1, Split 1 50.15% +/- 5.61%\n",
      "no stopwords removal, no_ngram, keep accents, Projection l2/l1, Split 2 38.90% +/- 4.52%\n",
      "no stopwords removal, no_ngram, keep accents, Projection l2/l1, Split 3 52.65% +/- 6.09%\n",
      "no stopwords removal, no_ngram, keep accents, Cosinus, Split 1 40.30% +/- 4.91%\n",
      "no stopwords removal, no_ngram, keep accents, Cosinus, Split 2 25.87% +/- 2.25%\n",
      "no stopwords removal, no_ngram, keep accents, Cosinus, Split 3 41.98% +/- 5.27%\n",
      "no stopwords removal, no_ngram, remove accents, Projection l2/l1, Split 1 49.47% +/- 5.77%\n",
      "no stopwords removal, no_ngram, remove accents, Projection l2/l1, Split 2 38.56% +/- 4.19%\n",
      "no stopwords removal, no_ngram, remove accents, Projection l2/l1, Split 3 52.02% +/- 6.05%\n",
      "no stopwords removal, no_ngram, remove accents, Cosinus, Split 1 40.93% +/- 5.02%\n",
      "no stopwords removal, no_ngram, remove accents, Cosinus, Split 2 26.06% +/- 2.00%\n",
      "no stopwords removal, no_ngram, remove accents, Cosinus, Split 3 42.68% +/- 5.42%\n",
      "no stopwords removal, bigrams, keep accents, Projection l2/l1, Split 1 55.47% +/- 5.22%\n",
      "no stopwords removal, bigrams, keep accents, Projection l2/l1, Split 2 43.12% +/- 2.32%\n",
      "no stopwords removal, bigrams, keep accents, Projection l2/l1, Split 3 58.38% +/- 5.06%\n",
      "no stopwords removal, bigrams, keep accents, Cosinus, Split 1 41.53% +/- 5.73%\n",
      "no stopwords removal, bigrams, keep accents, Cosinus, Split 2 26.94% +/- 2.14%\n",
      "no stopwords removal, bigrams, keep accents, Cosinus, Split 3 43.45% +/- 6.40%\n",
      "no stopwords removal, bigrams, remove accents, Projection l2/l1, Split 1 55.40% +/- 5.11%\n",
      "no stopwords removal, bigrams, remove accents, Projection l2/l1, Split 2 43.27% +/- 2.78%\n",
      "no stopwords removal, bigrams, remove accents, Projection l2/l1, Split 3 58.31% +/- 5.23%\n",
      "no stopwords removal, bigrams, remove accents, Cosinus, Split 1 41.49% +/- 5.88%\n",
      "no stopwords removal, bigrams, remove accents, Cosinus, Split 2 27.27% +/- 1.95%\n",
      "no stopwords removal, bigrams, remove accents, Cosinus, Split 3 43.70% +/- 6.48%\n",
      "no stopwords removal, trigrams, keep accents, Projection l2/l1, Split 1 56.41% +/- 5.05%\n",
      "no stopwords removal, trigrams, keep accents, Projection l2/l1, Split 2 43.75% +/- 3.06%\n",
      "no stopwords removal, trigrams, keep accents, Projection l2/l1, Split 3 59.56% +/- 5.12%\n",
      "no stopwords removal, trigrams, keep accents, Cosinus, Split 1 41.54% +/- 5.25%\n",
      "no stopwords removal, trigrams, keep accents, Cosinus, Split 2 26.95% +/- 2.41%\n",
      "no stopwords removal, trigrams, keep accents, Cosinus, Split 3 43.54% +/- 6.16%\n",
      "no stopwords removal, trigrams, remove accents, Projection l2/l1, Split 1 56.43% +/- 5.07%\n",
      "no stopwords removal, trigrams, remove accents, Projection l2/l1, Split 2 43.83% +/- 3.11%\n",
      "no stopwords removal, trigrams, remove accents, Projection l2/l1, Split 3 59.58% +/- 5.11%\n",
      "no stopwords removal, trigrams, remove accents, Cosinus, Split 1 42.08% +/- 5.14%\n",
      "no stopwords removal, trigrams, remove accents, Cosinus, Split 2 27.28% +/- 2.39%\n",
      "no stopwords removal, trigrams, remove accents, Cosinus, Split 3 44.18% +/- 6.17%\n",
      "with stopwords removal, no_ngram, keep accents, Projection l2/l1, Split 1 54.94% +/- 5.62%\n",
      "with stopwords removal, no_ngram, keep accents, Projection l2/l1, Split 2 42.12% +/- 4.32%\n",
      "with stopwords removal, no_ngram, keep accents, Projection l2/l1, Split 3 58.06% +/- 6.52%\n",
      "with stopwords removal, no_ngram, keep accents, Cosinus, Split 1 51.06% +/- 6.89%\n",
      "with stopwords removal, no_ngram, keep accents, Cosinus, Split 2 29.73% +/- 4.76%\n",
      "with stopwords removal, no_ngram, keep accents, Cosinus, Split 3 53.35% +/- 7.12%\n",
      "with stopwords removal, no_ngram, remove accents, Projection l2/l1, Split 1 54.89% +/- 5.81%\n",
      "with stopwords removal, no_ngram, remove accents, Projection l2/l1, Split 2 42.22% +/- 4.32%\n",
      "with stopwords removal, no_ngram, remove accents, Projection l2/l1, Split 3 57.99% +/- 6.66%\n",
      "with stopwords removal, no_ngram, remove accents, Cosinus, Split 1 51.40% +/- 6.72%\n",
      "with stopwords removal, no_ngram, remove accents, Cosinus, Split 2 30.44% +/- 4.69%\n",
      "with stopwords removal, no_ngram, remove accents, Cosinus, Split 3 53.69% +/- 7.13%\n",
      "with stopwords removal, bigrams, keep accents, Projection l2/l1, Split 1 57.74% +/- 5.74%\n",
      "with stopwords removal, bigrams, keep accents, Projection l2/l1, Split 2 44.54% +/- 3.57%\n",
      "with stopwords removal, bigrams, keep accents, Projection l2/l1, Split 3 61.08% +/- 5.91%\n",
      "with stopwords removal, bigrams, keep accents, Cosinus, Split 1 52.31% +/- 7.10%\n",
      "with stopwords removal, bigrams, keep accents, Cosinus, Split 2 26.86% +/- 4.47%\n",
      "with stopwords removal, bigrams, keep accents, Cosinus, Split 3 54.85% +/- 7.51%\n",
      "with stopwords removal, bigrams, remove accents, Projection l2/l1, Split 1 57.99% +/- 5.69%\n",
      "with stopwords removal, bigrams, remove accents, Projection l2/l1, Split 2 44.43% +/- 3.30%\n",
      "with stopwords removal, bigrams, remove accents, Projection l2/l1, Split 3 60.86% +/- 5.65%\n",
      "with stopwords removal, bigrams, remove accents, Cosinus, Split 1 51.79% +/- 6.83%\n",
      "with stopwords removal, bigrams, remove accents, Cosinus, Split 2 26.90% +/- 4.71%\n",
      "with stopwords removal, bigrams, remove accents, Cosinus, Split 3 54.43% +/- 7.18%\n",
      "with stopwords removal, trigrams, keep accents, Projection l2/l1, Split 1 58.76% +/- 5.47%\n",
      "with stopwords removal, trigrams, keep accents, Projection l2/l1, Split 2 45.36% +/- 3.58%\n",
      "with stopwords removal, trigrams, keep accents, Projection l2/l1, Split 3 61.94% +/- 5.59%\n",
      "with stopwords removal, trigrams, keep accents, Cosinus, Split 1 51.65% +/- 6.90%\n",
      "with stopwords removal, trigrams, keep accents, Cosinus, Split 2 25.74% +/- 4.50%\n",
      "with stopwords removal, trigrams, keep accents, Cosinus, Split 3 54.28% +/- 7.24%\n",
      "with stopwords removal, trigrams, remove accents, Projection l2/l1, Split 1 58.82% +/- 5.48%\n",
      "with stopwords removal, trigrams, remove accents, Projection l2/l1, Split 2 45.54% +/- 3.61%\n",
      "with stopwords removal, trigrams, remove accents, Projection l2/l1, Split 3 62.01% +/- 5.61%\n",
      "with stopwords removal, trigrams, remove accents, Cosinus, Split 1 51.54% +/- 6.74%\n",
      "with stopwords removal, trigrams, remove accents, Cosinus, Split 2 26.04% +/- 4.42%\n",
      "with stopwords removal, trigrams, remove accents, Cosinus, Split 3 54.26% +/- 7.21%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(search.cv_results_['rank_test_score'])):\n",
    "    str_result = f\"{search.cv_results_['mean_test_score'][i]:.2%} +/- {search.cv_results_['std_test_score'][i]:.2%}\"\n",
    "    print(labels[i], str_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On tire de ce premier test:\n",
    "- que le modèle est bien plus performant avec le retrait des stopwords\n",
    "- que le split le plus efficace est la fonction qui applique la regex (deux retours chariots parmi des whitespaces) - split 3\n",
    "- que la prise en compte de bigrammes améliore, avec les trigrammes en plus on ne gagne rien\n",
    "- que la similarité cosinus semble sensiblement moins performante que le choix par projection (l2/l1)\n",
    "\n",
    "Remarque : la standard dev est quand même assez élevée (de l'ordre de 5-6%). Les scénarios avec peu d'écart entre leurs moyennes (2-3%) ne sont pas départageables via cette grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application de la Grid Search : tuning du calcul de similarité\n",
    "\n",
    "On va maintenant déterminer, sur la base des paramètres déjà retenus, le mode de calcul de similarité le plus performant.\n",
    "Seul le calcul par projection est paramétrique (norme dans l'espace de départ vs. norme sur l'espace projeté), on fera uniquement varier ces paramètres (en plus de la comparaison avec la similarité cosinus).\n",
    "\n",
    "On comparera également la performance du modèle selon qu'on vectorise les textes via les comptes de mots, ou bien seulement via un identifiant binaire (présence ou absence du mot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 14 candidates, totalling 112 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 8 processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed:   36.6s finished\n"
     ]
    }
   ],
   "source": [
    "process_pipe.set_params(**{'Splitter__splitter_func': splitter_funcs[2],\n",
    "                           })\n",
    "\n",
    "kwargs_to_prod = prod_params({'stop_words': {'with stopwords removal' : stop_words},\n",
    "                              'ngram_range': {'bigrams': (1, 2)},\n",
    "                              'binary': {'counts': False, 'binary flag': True},\n",
    "                              'strip_accents': {'remove accents': 'unicode'}\n",
    "                             })\n",
    "\n",
    "param_grid = [{\n",
    "               'SimilaritySelector__source_norm': ['l2'],\n",
    "               'SimilaritySelector__projected_norm': ['l1'],\n",
    "               'SimilaritySelector__similarity': ['projection'],\n",
    "               'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "              },\n",
    "              {\n",
    "               'SimilaritySelector__similarity': ['projection'],\n",
    "               'SimilaritySelector__source_norm': ['l3'],\n",
    "               'SimilaritySelector__projected_norm': ['l2'],\n",
    "               'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "              },\n",
    "              {\n",
    "               'SimilaritySelector__similarity': ['projection'],\n",
    "               'SimilaritySelector__source_norm': ['l3'],\n",
    "               'SimilaritySelector__projected_norm': ['l1'],\n",
    "               'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "              },\n",
    "              {\n",
    "               'SimilaritySelector__similarity': ['projection'],\n",
    "               'SimilaritySelector__source_norm': ['l4'],\n",
    "               'SimilaritySelector__projected_norm': ['l3'],\n",
    "               'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "              },\n",
    "              {\n",
    "               'SimilaritySelector__similarity': ['projection'],\n",
    "               'SimilaritySelector__source_norm': ['l4'],\n",
    "               'SimilaritySelector__projected_norm': ['l2'],\n",
    "               'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "              },\n",
    "              {\n",
    "               'SimilaritySelector__similarity': ['projection'],\n",
    "               'SimilaritySelector__source_norm': ['l5'],\n",
    "               'SimilaritySelector__projected_norm': ['l4'],\n",
    "               'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "              },\n",
    "              {\n",
    "               'SimilaritySelector__similarity': ['cosine'],\n",
    "               'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "              }\n",
    "             ]\n",
    "search = GridSearchCV(process_pipe,\n",
    "                      param_grid,\n",
    "                      cv=8, \n",
    "                      scoring= lev_scorer,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1,\n",
    "                     ).fit(train, train['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2, l1, with stopwords removal, bigrams, counts, remove accents 60.86% +/- 5.65%\n",
      "l2, l1, with stopwords removal, bigrams, binary flag, remove accents 61.00% +/- 5.61%\n",
      "l3, l2, with stopwords removal, bigrams, counts, remove accents 61.55% +/- 5.25%\n",
      "l3, l2, with stopwords removal, bigrams, binary flag, remove accents 62.05% +/- 4.73%\n",
      "l3, l1, with stopwords removal, bigrams, counts, remove accents 59.33% +/- 5.34%\n",
      "l3, l1, with stopwords removal, bigrams, binary flag, remove accents 59.06% +/- 5.44%\n",
      "l4, l3, with stopwords removal, bigrams, counts, remove accents 59.61% +/- 4.00%\n",
      "l4, l3, with stopwords removal, bigrams, binary flag, remove accents 62.61% +/- 4.29%\n",
      "l4, l2, with stopwords removal, bigrams, counts, remove accents 61.11% +/- 5.30%\n",
      "l4, l2, with stopwords removal, bigrams, binary flag, remove accents 61.00% +/- 5.61%\n",
      "l5, l4, with stopwords removal, bigrams, counts, remove accents 56.23% +/- 3.40%\n",
      "l5, l4, with stopwords removal, bigrams, binary flag, remove accents 61.82% +/- 3.67%\n",
      "cosine, with stopwords removal, bigrams, counts, remove accents 54.43% +/- 7.18%\n",
      "cosine, with stopwords removal, bigrams, binary flag, remove accents 53.36% +/- 7.86%\n"
     ]
    }
   ],
   "source": [
    "labels = ['l2, l1',\n",
    "          'l3, l2', \n",
    "          'l3, l1',\n",
    "          'l4, l3',\n",
    "          'l4, l2',\n",
    "          'l5, l4',\n",
    "          'cosine',\n",
    "         ]\n",
    "\n",
    "labels = list(product(labels, kwargs_to_prod[0]))\n",
    "labels = list(map(lambda x: ', '.join(x), labels))\n",
    "\n",
    "for i in range(len(search.cv_results_['rank_test_score'])):\n",
    "    str_result = f\"{search.cv_results_['mean_test_score'][i]:.2%} +/- {search.cv_results_['std_test_score'][i]:.2%}\"\n",
    "    print(labels[i], str_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On tire de ce second test les conclusions suivantes :\n",
    "- comme lors du premier test, l'identification du meilleur candidat par similarité cosinus est moins performante que par projection\n",
    "- plusieurs configurations de paramètres permettent d'obtenir des performance similaires via la projection : \n",
    "    - l2/l1\n",
    "    - l2/l1b\n",
    "    - l3/l2\n",
    "    - l3/l2b\n",
    "    - l3/l1b\n",
    "    - l4/l2\n",
    "    - l4/l2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application de la Grid Search : impact des mots non vus en entrainement\n",
    "\n",
    "On va également voir si l'utilisation d'un vectorizer de type HashingVectorizer, qui permet de prendre en compte des mots non vus lors de l'entraînement a un impact sur la performance (ou son écart type, qui est très élevé...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 16 candidates, totalling 128 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 8 processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 128 out of 128 | elapsed:   43.1s finished\n"
     ]
    }
   ],
   "source": [
    "process_pipe.set_params(**{'Splitter__splitter_func': splitter_funcs[2],\n",
    "\n",
    "                           })\n",
    "\n",
    "kwargs_to_prod = prod_params({'stop_words': {'with stopwords removal' : stop_words},\n",
    "                              'ngram_range': {'bigrams': (1, 2)},\n",
    "                              'binary': {'counts': False, 'binary flag': True},\n",
    "                             })\n",
    "\n",
    "param_grid = [{'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "               'SimilaritySelector__count_vect_type': ['TfidfVectorizer', 'HashingVectorizer'],\n",
    "               'SimilaritySelector__similarity': ['projection'],\n",
    "               'SimilaritySelector__source_norm': ['l4'],\n",
    "               'SimilaritySelector__projected_norm': ['l2'],               \n",
    "              },\n",
    "              {'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "               'SimilaritySelector__count_vect_type': ['TfidfVectorizer', 'HashingVectorizer'],\n",
    "               'SimilaritySelector__similarity': ['projection'],               \n",
    "               'SimilaritySelector__source_norm': ['l3'],\n",
    "               'SimilaritySelector__projected_norm': ['l2'],\n",
    "              },\n",
    "              {'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "               'SimilaritySelector__count_vect_type': ['TfidfVectorizer', 'HashingVectorizer'],\n",
    "               'SimilaritySelector__similarity': ['projection'],               \n",
    "               'SimilaritySelector__source_norm': ['l2'],\n",
    "               'SimilaritySelector__projected_norm': ['l1'],\n",
    "              },\n",
    "              {'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "               'SimilaritySelector__count_vect_type': ['TfidfVectorizer', 'HashingVectorizer'],\n",
    "               'SimilaritySelector__similarity': ['cosine'],               \n",
    "              },\n",
    "             ]\n",
    "search = GridSearchCV(process_pipe,\n",
    "                      param_grid,\n",
    "                      cv=8, \n",
    "                      scoring= lev_scorer,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1,\n",
    "                     ).fit(train, train['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l4/l2, with stopwords removal, bigrams, counts, TfidfVectorizer 61.11% +/- 5.30%\n",
      "l4/l2, with stopwords removal, bigrams, counts, HashingVectorizer 61.07% +/- 5.23%\n",
      "l4/l2, with stopwords removal, bigrams, binary flag, TfidfVectorizer 61.00% +/- 5.61%\n",
      "l4/l2, with stopwords removal, bigrams, binary flag, HashingVectorizer 60.51% +/- 5.54%\n",
      "l3/l2, with stopwords removal, bigrams, counts, TfidfVectorizer 61.55% +/- 5.25%\n",
      "l3/l2, with stopwords removal, bigrams, counts, HashingVectorizer 59.97% +/- 5.25%\n",
      "l3/l2, with stopwords removal, bigrams, binary flag, TfidfVectorizer 62.05% +/- 4.73%\n",
      "l3/l2, with stopwords removal, bigrams, binary flag, HashingVectorizer 59.58% +/- 5.46%\n",
      "l2/l1, with stopwords removal, bigrams, counts, TfidfVectorizer 60.86% +/- 5.65%\n",
      "l2/l1, with stopwords removal, bigrams, counts, HashingVectorizer 60.36% +/- 5.89%\n",
      "l2/l1, with stopwords removal, bigrams, binary flag, TfidfVectorizer 61.00% +/- 5.61%\n",
      "l2/l1, with stopwords removal, bigrams, binary flag, HashingVectorizer 60.51% +/- 5.54%\n",
      "cosine, with stopwords removal, bigrams, counts, TfidfVectorizer 54.43% +/- 7.18%\n",
      "cosine, with stopwords removal, bigrams, counts, HashingVectorizer 53.01% +/- 6.20%\n",
      "cosine, with stopwords removal, bigrams, binary flag, TfidfVectorizer 53.36% +/- 7.86%\n",
      "cosine, with stopwords removal, bigrams, binary flag, HashingVectorizer 50.56% +/- 7.20%\n"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "          'l4/l2',\n",
    "          'l3/l2',\n",
    "          'l2/l1',\n",
    "          'cosine'\n",
    "         ]\n",
    "\n",
    "labels = list(product(labels, kwargs_to_prod[0], ['TfidfVectorizer', 'HashingVectorizer']))\n",
    "labels = list(map(lambda x: ', '.join(x), labels))\n",
    "\n",
    "for i in range(len(search.cv_results_['rank_test_score'])):\n",
    "    str_result = f\"{search.cv_results_['mean_test_score'][i]:.2%} +/- {search.cv_results_['std_test_score'][i]:.2%}\"\n",
    "    print(labels[i], str_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation d'un HashingVectorizer à la place d'un TfidfVectorizer, pour prendre en compte les mots non vus lors de l'entrainement, n'a pas d'impact positif sur la performance du modèle.\n",
    "Au contraire, elle semble globalement diminuer de quelques points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application d'une grid search : pondération des mots \n",
    "\n",
    "On va en plus appliquer une pondération absolue et relative des mots, dans la recherche de similarité par cosinus.\n",
    "\n",
    "Les différentes possibilités pour le vecteur cible sont : \n",
    "- moyenne des vecteurs de textes des listes d'ingrédients, avec uniquement un flag binaire (présence / absence du mot) : la cible est la document frequency moyenne des mots des listes d'ingrédients\n",
    "- moyenne des vecteurs de textes des listes d'ingrédients, avec en prenant en compte les comptes des mots dans chacun des textes : la cible est la term frequency moyenne des mots au sein des listes d'ingrédients\n",
    "- moyenne des scores \"absolus\" de chacun des mots au sein des listes d'ingrédients. Il s'agit d'une \"smooth document frequency\" (elle croit logarithmiquement)\n",
    "- moyenne des scores \"relatifs\" de chacun des mots entre liste d'ingrédients et contenu des fiches techniques. Ici on compare la doc frequency entre les deux corpus, pour donner plus de poids aux mots qui sont plus présents dans les listes d'ingrédients que dans le reste du corps du texte.\n",
    "\n",
    "On comparera à la projection l4/l2b, qui porte jusque là les meilleurs résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 32 candidates, totalling 256 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 8 processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 256 out of 256 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "process_pipe.set_params(**{'Splitter__splitter_func': splitter_funcs[2],\n",
    "                           'SimilaritySelector__count_vect_type': 'TfidfVectorizer',\n",
    "                           })\n",
    "\n",
    "kwargs_to_prod = prod_params({'stop_words': {'with stopwords removal' : stop_words},\n",
    "                              'ngram_range': {'no_ngrams': (1, 1), 'bigrams': (1, 2)},\n",
    "                              'binary': {'counts': False, 'binary flag': True},\n",
    "                              'use_idf': {'without idf': False, 'with idf': True},\n",
    "                              'strip_accents': {'remove accents': 'unicode'},\n",
    "                             })\n",
    "\n",
    "param_grid = [{\n",
    "               'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "               'SimilaritySelector__scoring': ['default', 'absolute_score', 'relative_score'],    \n",
    "               'SimilaritySelector__similarity': ['cosine'],\n",
    "              },\n",
    "              {'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "               'SimilaritySelector__scoring': ['default'],\n",
    "               'SimilaritySelector__similarity': ['projection'],\n",
    "               'SimilaritySelector__source_norm': ['l4'],\n",
    "               'SimilaritySelector__projected_norm': ['l2'],                   \n",
    "              },\n",
    "             ]\n",
    "search = GridSearchCV(process_pipe,\n",
    "                      param_grid,\n",
    "                      cv=8, \n",
    "                      scoring= lev_scorer,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1,\n",
    "                     ).fit(train, train['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine, with stopwords removal, no_ngrams, counts, without idf, remove accents, default 53.69% +/- 7.13%\n",
      "cosine, with stopwords removal, no_ngrams, counts, without idf, remove accents, absolute score 54.47% +/- 6.87%\n",
      "cosine, with stopwords removal, no_ngrams, counts, without idf, remove accents, relative score 29.42% +/- 5.32%\n",
      "cosine, with stopwords removal, no_ngrams, counts, with idf, remove accents, default 55.47% +/- 6.70%\n",
      "cosine, with stopwords removal, no_ngrams, counts, with idf, remove accents, absolute score 52.47% +/- 6.91%\n",
      "cosine, with stopwords removal, no_ngrams, counts, with idf, remove accents, relative score 32.73% +/- 5.21%\n",
      "cosine, with stopwords removal, no_ngrams, binary flag, without idf, remove accents, default 53.29% +/- 7.86%\n",
      "cosine, with stopwords removal, no_ngrams, binary flag, without idf, remove accents, absolute score 54.15% +/- 8.17%\n",
      "cosine, with stopwords removal, no_ngrams, binary flag, without idf, remove accents, relative score 28.02% +/- 5.00%\n",
      "cosine, with stopwords removal, no_ngrams, binary flag, with idf, remove accents, default 54.91% +/- 7.31%\n",
      "cosine, with stopwords removal, no_ngrams, binary flag, with idf, remove accents, absolute score 51.80% +/- 8.13%\n",
      "cosine, with stopwords removal, no_ngrams, binary flag, with idf, remove accents, relative score 31.39% +/- 5.59%\n",
      "cosine, with stopwords removal, bigrams, counts, without idf, remove accents, default 54.43% +/- 7.18%\n",
      "cosine, with stopwords removal, bigrams, counts, without idf, remove accents, absolute score 55.48% +/- 7.11%\n",
      "cosine, with stopwords removal, bigrams, counts, without idf, remove accents, relative score 33.39% +/- 6.11%\n",
      "cosine, with stopwords removal, bigrams, counts, with idf, remove accents, default 55.86% +/- 6.78%\n",
      "cosine, with stopwords removal, bigrams, counts, with idf, remove accents, absolute score 52.00% +/- 6.91%\n",
      "cosine, with stopwords removal, bigrams, counts, with idf, remove accents, relative score 39.00% +/- 5.38%\n",
      "cosine, with stopwords removal, bigrams, binary flag, without idf, remove accents, default 53.36% +/- 7.86%\n",
      "cosine, with stopwords removal, bigrams, binary flag, without idf, remove accents, absolute score 55.36% +/- 7.36%\n",
      "cosine, with stopwords removal, bigrams, binary flag, without idf, remove accents, relative score 32.74% +/- 5.87%\n",
      "cosine, with stopwords removal, bigrams, binary flag, with idf, remove accents, default 54.73% +/- 7.39%\n",
      "cosine, with stopwords removal, bigrams, binary flag, with idf, remove accents, absolute score 51.12% +/- 6.71%\n",
      "cosine, with stopwords removal, bigrams, binary flag, with idf, remove accents, relative score 39.45% +/- 5.47%\n",
      "projection l4/l2, with stopwords removal, no_ngrams, counts, without idf, remove accents 57.08% +/- 5.38%\n",
      "projection l4/l2, with stopwords removal, no_ngrams, counts, with idf, remove accents 40.27% +/- 2.56%\n",
      "projection l4/l2, with stopwords removal, no_ngrams, binary flag, without idf, remove accents 57.26% +/- 5.89%\n",
      "projection l4/l2, with stopwords removal, no_ngrams, binary flag, with idf, remove accents 45.13% +/- 5.16%\n",
      "projection l4/l2, with stopwords removal, bigrams, counts, without idf, remove accents 61.11% +/- 5.30%\n",
      "projection l4/l2, with stopwords removal, bigrams, counts, with idf, remove accents 49.79% +/- 5.24%\n",
      "projection l4/l2, with stopwords removal, bigrams, binary flag, without idf, remove accents 61.00% +/- 5.61%\n",
      "projection l4/l2, with stopwords removal, bigrams, binary flag, with idf, remove accents 51.93% +/- 6.79%\n"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "          'cosine',\n",
    "         ]\n",
    "\n",
    "\n",
    "labels = list(product(labels, kwargs_to_prod[0], ['default', 'absolute score', 'relative score']))\n",
    "labels.extend(list(product(['projection l4/l2'],  kwargs_to_prod[0])))\n",
    "labels = list(map(lambda x: ', '.join(x), labels))\n",
    "\n",
    "for i in range(len(search.cv_results_['rank_test_score'])):\n",
    "    str_result = f\"{search.cv_results_['mean_test_score'][i]:.2%} +/- {search.cv_results_['std_test_score'][i]:.2%}\"\n",
    "    print(labels[i], str_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.04464698, 1.11869857, 1.38373205, 0.7387183 , 0.99120578,\n",
       "        1.4639748 , 0.70843965, 0.8971028 , 1.28756195, 0.74357998,\n",
       "        0.91837344, 1.26502818, 1.15127203, 1.58092356, 2.05790946,\n",
       "        1.1457637 , 1.53968149, 2.02482742, 1.18108353, 1.59118012,\n",
       "        2.13614097, 1.2229169 , 1.59080085, 2.14523304, 0.78127733,\n",
       "        0.64556399, 0.62803563, 0.61303991, 0.97116473, 1.0362848 ,\n",
       "        1.06738931, 0.99505311]),\n",
       " 'std_fit_time': array([0.09646691, 0.12062726, 0.13310404, 0.12761933, 0.10728558,\n",
       "        0.11898674, 0.10610455, 0.0447356 , 0.11340495, 0.11330933,\n",
       "        0.05391361, 0.12981145, 0.11105268, 0.08852161, 0.13011447,\n",
       "        0.15965745, 0.08680976, 0.10783568, 0.09796659, 0.14748077,\n",
       "        0.14729109, 0.0783453 , 0.11034447, 0.13701008, 0.201603  ,\n",
       "        0.03673408, 0.01226879, 0.02465827, 0.08458008, 0.07782379,\n",
       "        0.09005581, 0.08323097]),\n",
       " 'mean_score_time': array([0.42370096, 0.3385323 , 0.43205762, 0.35798511, 0.38235608,\n",
       "        0.40525657, 0.30328706, 0.31151748, 0.38374534, 0.33924416,\n",
       "        0.36717439, 0.39248583, 0.4632912 , 0.57266936, 0.5870927 ,\n",
       "        0.54204151, 0.59328398, 0.61395833, 0.55259615, 0.56867296,\n",
       "        0.61494726, 0.57295623, 0.62147921, 0.62011668, 0.30000687,\n",
       "        0.31538019, 0.27458903, 0.29090267, 0.36211008, 0.41245037,\n",
       "        0.3592574 , 0.36498883]),\n",
       " 'std_score_time': array([0.04547827, 0.04307329, 0.04969008, 0.07768429, 0.033981  ,\n",
       "        0.03168766, 0.05723885, 0.02549282, 0.04869049, 0.03295988,\n",
       "        0.05153402, 0.04716431, 0.04445023, 0.05339806, 0.02476675,\n",
       "        0.04202467, 0.02460749, 0.03825711, 0.08904062, 0.05087402,\n",
       "        0.07672192, 0.07076118, 0.04521163, 0.03220029, 0.07645433,\n",
       "        0.01577731, 0.00920112, 0.01414946, 0.0430331 , 0.02051531,\n",
       "        0.04385852, 0.03287497]),\n",
       " 'param_SimilaritySelector__count_vect_kwargs': masked_array(data=[{'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': False, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': False, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': False, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': False, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': False, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': False, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': True, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': True, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': True, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': True, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': True, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': True, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': False, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': False, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': False, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': False, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': False, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': False, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': True, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': True, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': True, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': True, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': True, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': True, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': False, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': False, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': True, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 1), 'binary': True, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': False, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': False, 'use_idf': True, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': True, 'use_idf': False, 'strip_accents': 'unicode'},\n",
       "                    {'stop_words': {'un', 'les', 'des', 'la', 'en', 'pour', 'le', 'et', 'que', 'and', 'ou', 'sur', 'par', 'dans', 'de', 'dont', 'est', 'pas', 'du', 'of', 'ce', 'au'}, 'ngram_range': (1, 2), 'binary': True, 'use_idf': True, 'strip_accents': 'unicode'}],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_SimilaritySelector__scoring': masked_array(data=['default', 'absolute_score', 'relative_score',\n",
       "                    'default', 'absolute_score', 'relative_score',\n",
       "                    'default', 'absolute_score', 'relative_score',\n",
       "                    'default', 'absolute_score', 'relative_score',\n",
       "                    'default', 'absolute_score', 'relative_score',\n",
       "                    'default', 'absolute_score', 'relative_score',\n",
       "                    'default', 'absolute_score', 'relative_score',\n",
       "                    'default', 'absolute_score', 'relative_score',\n",
       "                    'default', 'default', 'default', 'default', 'default',\n",
       "                    'default', 'default', 'default'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_SimilaritySelector__similarity': masked_array(data=['cosine', 'cosine', 'cosine', 'cosine', 'cosine',\n",
       "                    'cosine', 'cosine', 'cosine', 'cosine', 'cosine',\n",
       "                    'cosine', 'cosine', 'cosine', 'cosine', 'cosine',\n",
       "                    'cosine', 'cosine', 'cosine', 'cosine', 'cosine',\n",
       "                    'cosine', 'cosine', 'cosine', 'cosine', 'projection',\n",
       "                    'projection', 'projection', 'projection', 'projection',\n",
       "                    'projection', 'projection', 'projection'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_SimilaritySelector__projected_norm': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_SimilaritySelector__source_norm': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'l4', 'l4',\n",
       "                    'l4', 'l4', 'l4', 'l4', 'l4', 'l4'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': False,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': False,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'absolute_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': False,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'relative_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': False,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': False,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'absolute_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': False,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'relative_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': True,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': True,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'absolute_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': True,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'relative_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': True,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': True,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'absolute_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': True,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'relative_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': False,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': False,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'absolute_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': False,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'relative_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': False,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': False,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'absolute_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': False,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'relative_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': True,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': True,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'absolute_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': True,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'relative_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': True,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': True,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'absolute_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': True,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__scoring': 'relative_score',\n",
       "   'SimilaritySelector__similarity': 'cosine'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': False,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__projected_norm': 'l2',\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'SimilaritySelector__source_norm': 'l4'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': False,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__projected_norm': 'l2',\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'SimilaritySelector__source_norm': 'l4'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': True,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__projected_norm': 'l2',\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'SimilaritySelector__source_norm': 'l4'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 1),\n",
       "    'binary': True,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__projected_norm': 'l2',\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'SimilaritySelector__source_norm': 'l4'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': False,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__projected_norm': 'l2',\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'SimilaritySelector__source_norm': 'l4'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': False,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__projected_norm': 'l2',\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'SimilaritySelector__source_norm': 'l4'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': True,\n",
       "    'use_idf': False,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__projected_norm': 'l2',\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'SimilaritySelector__source_norm': 'l4'},\n",
       "  {'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "     'au',\n",
       "     'ce',\n",
       "     'dans',\n",
       "     'de',\n",
       "     'des',\n",
       "     'dont',\n",
       "     'du',\n",
       "     'en',\n",
       "     'est',\n",
       "     'et',\n",
       "     'la',\n",
       "     'le',\n",
       "     'les',\n",
       "     'of',\n",
       "     'ou',\n",
       "     'par',\n",
       "     'pas',\n",
       "     'pour',\n",
       "     'que',\n",
       "     'sur',\n",
       "     'un'},\n",
       "    'ngram_range': (1, 2),\n",
       "    'binary': True,\n",
       "    'use_idf': True,\n",
       "    'strip_accents': 'unicode'},\n",
       "   'SimilaritySelector__projected_norm': 'l2',\n",
       "   'SimilaritySelector__scoring': 'default',\n",
       "   'SimilaritySelector__similarity': 'projection',\n",
       "   'SimilaritySelector__source_norm': 'l4'}],\n",
       " 'split0_test_score': array([0.43378343, 0.43560161, 0.25051489, 0.4800957 , 0.44468526,\n",
       "        0.28882988, 0.43399291, 0.4207622 , 0.26060186, 0.43431512,\n",
       "        0.4207622 , 0.26060186, 0.44468526, 0.46425192, 0.29561299,\n",
       "        0.49362573, 0.45783593, 0.36077909, 0.44446475, 0.46716889,\n",
       "        0.27530428, 0.47361542, 0.46032291, 0.35162021, 0.57978323,\n",
       "        0.37956357, 0.54109085, 0.39844702, 0.58068664, 0.5466826 ,\n",
       "        0.57918809, 0.5513901 ]),\n",
       " 'split1_test_score': array([0.64240212, 0.63793477, 0.25022548, 0.65144111, 0.63857659,\n",
       "        0.25022548, 0.63611659, 0.65699614, 0.231734  , 0.65699614,\n",
       "        0.63857659, 0.231734  , 0.64816604, 0.66758773, 0.23022548,\n",
       "        0.65312119, 0.62391881, 0.31437995, 0.65883768, 0.66660166,\n",
       "        0.25022548, 0.64785247, 0.62391881, 0.38347966, 0.6156442 ,\n",
       "        0.41303756, 0.64340005, 0.50785594, 0.66902195, 0.57718385,\n",
       "        0.67774199, 0.5748363 ]),\n",
       " 'split2_test_score': array([0.46554372, 0.46867376, 0.25041253, 0.47852595, 0.49212715,\n",
       "        0.3108892 , 0.44474273, 0.45978918, 0.27430039, 0.49429302,\n",
       "        0.48128736, 0.31173354, 0.47895215, 0.4791769 , 0.33650255,\n",
       "        0.46919531, 0.496019  , 0.37067885, 0.47979847, 0.47915453,\n",
       "        0.3603904 , 0.49599664, 0.47356933, 0.37165998, 0.48079902,\n",
       "        0.37580402, 0.47028688, 0.37778414, 0.52046834, 0.40617399,\n",
       "        0.51643209, 0.39978173]),\n",
       " 'split3_test_score': array([0.52722013, 0.53923676, 0.40798811, 0.55887962, 0.51941694,\n",
       "        0.42655953, 0.55976891, 0.55976891, 0.3702489 , 0.55976891,\n",
       "        0.53737858, 0.42655953, 0.56019632, 0.56019632, 0.42655953,\n",
       "        0.56019632, 0.51941694, 0.45803534, 0.54418478, 0.57941177,\n",
       "        0.42655953, 0.5481806 , 0.49093511, 0.46784527, 0.54379393,\n",
       "        0.40340763, 0.56281564, 0.47859013, 0.57335954, 0.48032334,\n",
       "        0.59022245, 0.53662431]),\n",
       " 'split4_test_score': array([0.64960102, 0.64855051, 0.26319857, 0.66799676, 0.62336777,\n",
       "        0.30790004, 0.65571106, 0.66270699, 0.26354951, 0.66270699,\n",
       "        0.63647375, 0.30825097, 0.66270699, 0.66165649, 0.28219936,\n",
       "        0.67347851, 0.63281426, 0.36979615, 0.64842692, 0.66270699,\n",
       "        0.28219936, 0.67360675, 0.60479403, 0.33649255, 0.6724579 ,\n",
       "        0.45855138, 0.67109831, 0.53114374, 0.68527049, 0.51669311,\n",
       "        0.70078069, 0.60640277]),\n",
       " 'split5_test_score': array([0.54022324, 0.52467654, 0.34831762, 0.53463728, 0.43589273,\n",
       "        0.38012082, 0.46307958, 0.48250155, 0.34831762, 0.53560426,\n",
       "        0.40497935, 0.36364452, 0.5195918 , 0.52342654, 0.38646604,\n",
       "        0.53577314, 0.42194106, 0.39632053, 0.43948109, 0.50050847,\n",
       "        0.38788383, 0.4621105 , 0.41617276, 0.41491198, 0.53915423,\n",
       "        0.3909283 , 0.54342735, 0.40320745, 0.60065173, 0.47580252,\n",
       "        0.5931662 , 0.4666159 ]),\n",
       " 'split6_test_score': array([0.50670174, 0.54449643, 0.29129568, 0.51029703, 0.51636731,\n",
       "        0.30486711, 0.51796745, 0.53375843, 0.27734917, 0.50888595,\n",
       "        0.50075775, 0.29977774, 0.51029703, 0.51935654, 0.32095752,\n",
       "        0.51585014, 0.49706226, 0.35903613, 0.50888595, 0.50888595,\n",
       "        0.28620631, 0.50537955, 0.48659167, 0.33929254, 0.54671447,\n",
       "        0.38271416, 0.55611808, 0.44264697, 0.5956834 , 0.44732408,\n",
       "        0.57976647, 0.44738072]),\n",
       " 'split7_test_score': array([0.53007936, 0.55875305, 0.29197456, 0.55589915, 0.52750985,\n",
       "        0.34917834, 0.55183071, 0.55536012, 0.21568402, 0.54028713,\n",
       "        0.52411692, 0.30855819, 0.53007936, 0.56262618, 0.39243805,\n",
       "        0.5675412 , 0.51075387, 0.49078841, 0.54439535, 0.56407052,\n",
       "        0.35050316, 0.57144836, 0.53362816, 0.49078841, 0.58777767,\n",
       "        0.41772216, 0.59247525, 0.47109029, 0.6633407 , 0.53275234,\n",
       "        0.64300779, 0.57123984]),\n",
       " 'mean_test_score': array([0.53694434, 0.54474043, 0.29424093, 0.55472158, 0.52474295,\n",
       "        0.3273213 , 0.53290124, 0.54145544, 0.28022318, 0.54910719,\n",
       "        0.51804156, 0.31385754, 0.54433437, 0.55478483, 0.33387019,\n",
       "        0.55859769, 0.51997027, 0.3899768 , 0.53355937, 0.5535636 ,\n",
       "        0.32740905, 0.54727379, 0.5112416 , 0.39451133, 0.57076558,\n",
       "        0.4027161 , 0.57258905, 0.45134571, 0.61106035, 0.49786698,\n",
       "        0.61003822, 0.51928396]),\n",
       " 'std_test_score': array([0.07125671, 0.06872809, 0.05316296, 0.06704133, 0.06906384,\n",
       "        0.05207025, 0.07863581, 0.08166345, 0.0499554 , 0.07307385,\n",
       "        0.0812878 , 0.05592763, 0.07178389, 0.07105288, 0.06107087,\n",
       "        0.06780237, 0.06909518, 0.05378147, 0.07858682, 0.07355279,\n",
       "        0.05865462, 0.07392913, 0.06710005, 0.05472905, 0.05376492,\n",
       "        0.02561518, 0.05893728, 0.0515943 , 0.05302775, 0.05244324,\n",
       "        0.05613882, 0.06794431]),\n",
       " 'rank_test_score': array([14, 11, 31,  7, 17, 29, 16, 13, 32,  9, 20, 30, 12,  6, 27,  5, 18,\n",
       "        26, 15,  8, 28, 10, 21, 25,  4, 24,  3, 23,  1, 22,  2, 19],\n",
       "       dtype=int32)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en déduit :\n",
    "- que la similarité par projection reste le mode de détermination du candidat le plus efficace\n",
    "- que dans ce mode, l'utilisation de l'idf dégrade la performance\n",
    "- néanmoins, dans le cadre de la similarité cosinus, l'utilisation de l'idf a un impact positif pour la fonction de scoring par défaut, ou relative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application de la grid search : embeddings des mots\n",
    "\n",
    "On mesure l'impact sur la performance de l'utilisation d'embeddings de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 18 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   21.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 8 processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "process_pipe.set_params(**{'Splitter__splitter_func': splitter_funcs[2],\n",
    "                           'SimilaritySelector__count_vect_type': 'TfidfVectorizer',\n",
    "                           })\n",
    "\n",
    "kwargs_to_prod = prod_params({'stop_words': {'with stopwords removal' : stop_words},\n",
    "                              'ngram_range': {'no_ngram': (1, 1)},\n",
    "                              'binary': {'counts': False, 'binary flag': True},           \n",
    "                              'strip_accents': {'remove accents': 'unicode'},\n",
    "                             })\n",
    "\n",
    "param_grid = [{\n",
    "               'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "               'SimilaritySelector__scoring': ['default', 'absolute_score', 'relative_score'],    \n",
    "               'SimilaritySelector__similarity': ['cosine'],\n",
    "               'SimilaritySelector__embedding_method': [None, 'Word2Vec', 'tSVD'],\n",
    "              },\n",
    "             ]\n",
    "search = GridSearchCV(process_pipe,\n",
    "                      param_grid,\n",
    "                      cv=8, \n",
    "                      scoring= lev_scorer,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1,\n",
    "                      error_score='raise',\n",
    "                     ).fit(train, train['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with stopwords removal, no_ngram, counts, remove accents, No embed, default 53.69% +/- 7.13%\n",
      "with stopwords removal, no_ngram, counts, remove accents, No embed, absolute score 54.47% +/- 6.87%\n",
      "with stopwords removal, no_ngram, counts, remove accents, No embed, relative score 29.42% +/- 5.32%\n",
      "with stopwords removal, no_ngram, counts, remove accents, Word2Vec, default 53.57% +/- 4.97%\n",
      "with stopwords removal, no_ngram, counts, remove accents, Word2Vec, absolute score 52.97% +/- 5.81%\n",
      "with stopwords removal, no_ngram, counts, remove accents, Word2Vec, relative score 10.18% +/- 2.67%\n",
      "with stopwords removal, no_ngram, counts, remove accents, tSVD, default 50.95% +/- 7.02%\n",
      "with stopwords removal, no_ngram, counts, remove accents, tSVD, absolute score 50.11% +/- 7.72%\n",
      "with stopwords removal, no_ngram, counts, remove accents, tSVD, relative score 8.43% +/- 1.01%\n",
      "with stopwords removal, no_ngram, binary flag, remove accents, No embed, default 53.29% +/- 7.86%\n",
      "with stopwords removal, no_ngram, binary flag, remove accents, No embed, absolute score 54.15% +/- 8.17%\n",
      "with stopwords removal, no_ngram, binary flag, remove accents, No embed, relative score 28.02% +/- 5.00%\n",
      "with stopwords removal, no_ngram, binary flag, remove accents, Word2Vec, default 52.82% +/- 5.55%\n",
      "with stopwords removal, no_ngram, binary flag, remove accents, Word2Vec, absolute score 51.89% +/- 5.54%\n",
      "with stopwords removal, no_ngram, binary flag, remove accents, Word2Vec, relative score 10.20% +/- 2.68%\n",
      "with stopwords removal, no_ngram, binary flag, remove accents, tSVD, default 53.69% +/- 8.49%\n",
      "with stopwords removal, no_ngram, binary flag, remove accents, tSVD, absolute score 54.71% +/- 7.93%\n",
      "with stopwords removal, no_ngram, binary flag, remove accents, tSVD, relative score 9.28% +/- 2.19%\n"
     ]
    }
   ],
   "source": [
    "labels = ['default', 'absolute_score', 'relative_score']\n",
    "\n",
    "\n",
    "labels = list(product(kwargs_to_prod[0],\n",
    "                      ['No embed', 'Word2Vec', 'tSVD'],\n",
    "                      ['default', 'absolute score', 'relative score'],\n",
    "                     ))\n",
    "# labels.extend(list(product(['projection l4/l2'],  kwargs_to_prod[0])))\n",
    "labels = list(map(lambda x: ', '.join(x), labels))\n",
    "\n",
    "for i in range(len(search.cv_results_['rank_test_score'])):\n",
    "    str_result = f\"{search.cv_results_['mean_test_score'][i]:.2%} +/- {search.cv_results_['std_test_score'][i]:.2%}\"\n",
    "    print(labels[i], str_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SimilaritySelector__count_vect_kwargs': {'stop_words': {'and',\n",
       "   'au',\n",
       "   'ce',\n",
       "   'dans',\n",
       "   'de',\n",
       "   'des',\n",
       "   'dont',\n",
       "   'du',\n",
       "   'en',\n",
       "   'est',\n",
       "   'et',\n",
       "   'la',\n",
       "   'le',\n",
       "   'les',\n",
       "   'of',\n",
       "   'ou',\n",
       "   'par',\n",
       "   'pas',\n",
       "   'pour',\n",
       "   'que',\n",
       "   'sur',\n",
       "   'un'},\n",
       "  'ngram_range': (1, 1),\n",
       "  'binary': True,\n",
       "  'strip_accents': 'unicode'},\n",
       " 'SimilaritySelector__embedding_method': 'tSVD',\n",
       " 'SimilaritySelector__scoring': 'absolute_score',\n",
       " 'SimilaritySelector__similarity': 'cosine'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search : validation finale de l'ensemble des critères\n",
    "\n",
    "On applique enfin une random search, afin de voir si les conclusions qui avaient été tirée lors des explorations systématiques de certains domaines sont viables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 50 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 8 processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  4.0min finished\n"
     ]
    }
   ],
   "source": [
    "kwargs_to_prod = prod_params({'stop_words': {'with stopwords removal' : stop_words, 'keep stopwords': None},\n",
    "                              'use_idf': {'with idf': True, 'no idf': False},\n",
    "                              'binary': {'counts': False, 'binary flag': True},                                       \n",
    "                              'ngram_range': {'no_ngram': (1, 1), 'bigrams': (1, 2), 'trigrams': (1, 3)},  \n",
    "                              'strip_accents': {'remove accents': 'unicode', 'keep accents': None},\n",
    "                             })\n",
    "param_grid = [{\n",
    "               'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "               'SimilaritySelector__scoring': ['default', 'absolute_score', 'relative_score'],    \n",
    "               'SimilaritySelector__similarity': ['cosine'],\n",
    "               'SimilaritySelector__embedding_method': [None, 'Word2Vec', 'tSVD'],\n",
    "    \n",
    "              },\n",
    "              {'SimilaritySelector__count_vect_kwargs': kwargs_to_prod[1],\n",
    "               'SimilaritySelector__scoring': ['default'],\n",
    "               'SimilaritySelector__similarity': ['projection'],\n",
    "               'SimilaritySelector__source_norm': ['l2', 'l3', 'l4', 'l5'],\n",
    "               'SimilaritySelector__projected_norm': ['l1', 'l2', 'l3', 'l4'],                   \n",
    "              },\n",
    "             ]\n",
    "len(kwargs_to_prod[1])\n",
    "\n",
    "search = RandomizedSearchCV(process_pipe,\n",
    "                            param_grid,\n",
    "                            n_iter=50,\n",
    "                            cv=8, \n",
    "                            scoring= lev_scorer,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1,\n",
    "                           ).fit(train, train['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SimilaritySelector__source_norm': 'l5',\n",
       " 'SimilaritySelector__similarity': 'projection',\n",
       " 'SimilaritySelector__scoring': 'default',\n",
       " 'SimilaritySelector__projected_norm': 'l3',\n",
       " 'SimilaritySelector__count_vect_kwargs': {'stop_words': None,\n",
       "  'use_idf': False,\n",
       "  'binary': True,\n",
       "  'ngram_range': (1, 2),\n",
       "  'strip_accents': None}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6091800832952281"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
